#!/usr/bin/env python3
"""
Waffle Brain AI æ–°é—»ç½‘ç«™çˆ¬è™«
çˆ¬å–ä¸»æµ AI åª’ä½“çš„æœ€æ–°æ–°é—»å’Œè¡Œä¸šåŠ¨æ€
"""

import json
import time
import os
import re

# é…ç½®è¾“å‡ºåˆ° JSON æ–‡ä»¶
OUTPUT_FILE = "crawled_data/ai_news.json"
os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

# AI æ–°é—»ç½‘ç«™åˆ—è¡¨ï¼ˆçŸ¥åçš„ AI åª’ä½“å’Œè¡Œä¸šæ–°é—»æºï¼‰
NEWS_SOURCES = {
    "TechCrunch": {
        "name": "TechCrunch",
        "url": "https://techcrunch.com/category/artificial-intelligence/",
        "selector": ".post-block-title",
        "title_selector": ".post-block-title a",
        "description_selector": ".post-excerpt p",
        "link_selector": ".post-block-permalink",
        "date_selector": "time .datetime"
    },
    "VentureBeat": {
        "name": "VentureBeat",
        "url": "https://venturebeat.com/category/ai/",
        "selector": ".article-title",
        "title_selector": ".article-title",
        "description_selector": ".article-excerpt p",
        "link_selector": ".article-permalink",
        "date_selector": "time .datetime"
    },
    "The Verge": {
        "name": "The Verge",
        "url": "https://www.theverge.com/ai-artificial-intelligence/",
        "selector": ".c-entry-box-header__title",
        "title_selector": ".c-entry-box-header__title",
        "description_selector": ".c-entry-box-excerpt p",
        "link_selector": ".c-entry-box-read-more",
        "date_selector": "time .datetime"
    },
    "AI News": {
        "name": "AI News",
        "url": "https://www.artificialintelligence.news/",
        "selector": "article-title",
        "title_selector": ".article-title",
        "description_selector": ".article-excerpt p",
        "link_selector": ".article-read-more",
        "date_selector": ".date-meta"
    },
    "Synced Review": {
        "name": "Synced Review",
        "url": "https://www.syncedreview.com/category/ai/",
        "selector": ".entry-title",
        "title_selector": ".entry-title",
        "description_selector": ".entry-excerpt p",
        "link_selector": ".entry-permalink",
        "date_selector": ".entry-meta-date"
    }
}

def extract_date(date_str):
    """æå–æ—¥æœŸå­—ç¬¦ä¸²"""
    # ç§»é™¤å¤šä½™çš„ç©ºç™½
    date_str = date_str.strip()
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    for fmt in ['%Y-%m-%d', '%B %d, %Y', '%d %B %Y']:
        try:
            time_obj = time.strptime(date_str, fmt)
            return time_obj.strftime("%Y-%m-%d")
        except:
            pass
    return date_str

def crawl_news_source(source_name, source_info):
    """çˆ¬å–æŒ‡å®šæ–°é—»æºçš„æœ€æ–°æ–‡ç« """
    articles = []
    
    print(f"æ­£åœ¨çˆ¬å– {source_name} çš„æœ€æ–°æ–°é—»...")
    
    # æ¨¡æ‹Ÿçˆ¬å–è¿‡ç¨‹ï¼ˆå®é™…ä½¿ç”¨éœ€è¦ requests + BeautifulSoupï¼‰
    for i in range(10):  # æ¨¡æ‹Ÿçˆ¬å– 10 ç¯‡æ–‡ç« 
        article = {
            "source": source_name,
            "title": f"AI çªç ´ï¼šæ–°ä¸€ä»£å¤šæ¨¡æ€æ¨¡å‹æ”¹å˜è¡Œä¸šæ ¼å±€ - ç¬¬ {i+1} ç¯‡æ¨¡æ‹Ÿ",
            "description": f"è¿™æ˜¯ç¬¬ {i+1} ç¯‡æ¨¡æ‹Ÿæ–°é—»æ‘˜è¦ã€‚æ–°ä¸€ä»£å¤šæ¨¡æ€ AI ç³»ç»Ÿèƒ½å¤ŸåŒæ—¶ç†è§£å’Œå¤„ç†æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ç­‰å¤šç§ç±»å‹çš„æ•°æ®ï¼Œè¿™ä¸€çªç ´å°†æå¤§æ¨åŠ¨ AI åº”ç”¨çš„å‘å±•ã€‚ä¸“å®¶è¡¨ç¤ºï¼Œè¿™å°†ä½¿ AI ç³»ç»Ÿæ›´åŠ æ™ºèƒ½å’Œé€šç”¨ï¼Œä¸ºå„è¡Œå„ä¸šå¸¦æ¥æ–°çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚",
            "category": "breakthrough",
            "url": f"https://example.com/article-{i}",
            "date": time.strftime("%Y-%m-%d"),
            "author": source_name
        }
        articles.append(article)
        time.sleep(0.5)
    
    return articles

def main():
    """ä¸»å‡½æ•°"""
    all_articles = []
    
    for source_name, source_info in NEWS_SOURCES.items():
        articles = crawl_news_source(source_name, source_info)
        all_articles.extend(articles)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump({
            "crawled_at": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "sources": list(NEWS_SOURCES.keys()),
            "articles": all_articles
        }, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æˆåŠŸçˆ¬å– {len(all_articles)} ç¯‡æ–‡ç« ")
    print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
