#!/usr/bin/env python3
"""
Waffle Brain X (Twitter) çˆ¬è™«
çˆ¬å– AI è¡Œä¸šçŸ¥åè´¦å·çš„æ¨æ–‡å’Œå’¨è¯¢
"""

import json
import time
import os

# é…ç½®è¾“å‡ºåˆ° JSON æ–‡ä»¶
OUTPUT_FILE = "crawled_data/x_ai_tweets.json"
os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

# è¦çˆ¬å–çš„è´¦å·åˆ—è¡¨ï¼ˆçŸ¥å AI è¡Œä¸šè´¦å·ï¼‰
ACCOUNTS_TO_CRAWL = [
    "OpenAI",
    "AnthropicAI", 
    "GoogleDeepMind",
    "PerplexityAI",
    "RunwayML",
    "StabilityAI",
    "Midjourney",
    "NVIDIA",
    "AIatMeta",
    "xAI",
    "GeminiAI",
    "HuggingFace",
    "ElevenLabs"
]

def extract_tweet_text(tweet):
    """æå–æ¨æ–‡çš„æ ¸å¿ƒå†…å®¹"""
    return tweet.get('text', '')

def crawl_x_ai_tweets(account, limit=20):
    """
    çˆ¬å–æŒ‡å®šè´¦å·çš„æœ€æ–°æ¨æ–‡
    æ³¨æ„ï¼šè¿™æ˜¯æ¨¡æ‹Ÿç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨éœ€è¦ Twitter API
    """
    tweets = []
    
    for i in range(limit):
        tweet = {
            "account": account,
            "text": f"è¿™æ˜¯ç¬¬ {i+1} æ¡æ¨¡æ‹Ÿæ¨æ–‡ï¼š{account} åˆ†äº«äº†æœ€æ–°çš„ AI åŠŸèƒ½æ›´æ–°ã€‚",
            "date": time.strftime("%Y-%m-%d"),
            "likes": f"{1000 + i * 50}",
            "retweets": f"{200 + i * 30}",
            "replies": f"{50 + i * 10}",
            "url": f"https://twitter.com/{account}/status/{12345678 + i}"
        }
        tweets.append(tweet)
        time.sleep(1)
    
    return tweets

def main():
    """ä¸»å‡½æ•°"""
    all_tweets = []
    
    for account in ACCOUNTS_TO_CRAWL:
        print(f"æ­£åœ¨çˆ¬å– {account} çš„æ¨æ–‡...")
        tweets = crawl_x_ai_tweets(account)
        all_tweets.extend(tweets)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump({
            "crawled_at": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "source": "X/Twitter (Mock)",
            "tweets": all_tweets
        }, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æˆåŠŸçˆ¬å– {len(all_tweets)} æ¡æ¨æ–‡")
    print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
